\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}  
\usepackage{algorithmicx}  
\usepackage{algpseudocode}  
\usepackage{amsmath}  
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{Predicting MBTI Personality Type Based on Social Media Record}

\author{
Xinyi Cai\\
2018533085\\
{\tt\small caixy@shanghaitech.edu.cn}
\and
Beiyuan Yang\\
39132991\\
{\tt\small yangby@shanghaitech.edu.cn}
\and 
Wenhui Qiao\\
57425238\\
{\tt\small qiaowh@shanghaitech.edu.cn}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
   Board Games always push the player not only consider 
   how to do the local optimal decision at current 
   state, but also ask the plaer to guess  how will 
   his opponent will perform in the next state. MiniMax 
   tree is one of the basic idea to consider the states 
   in the future. However, MiniMax tree has high time 
   complexity and hard to define the reward and its 
   parameters, only use MiniMax tree in an agent is hard 
   to perform well. 
   
   
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}


In the general board games, it has initial states 
$s_{0}$, and other states $s_{t}$ at \emph{t} time. Two players denoted as 
$p_{1}$ and $p_{2}$. its next action set depends on the current 
state $action\left(s_{t}, p_{i}\right) = \left\{PointPosition\right\}$. 
With specific rules, update function, \emph{Update}$\left(s_{t}, p_{i}, action \right)$ to update the chess board. 
$s_{t}$ = \emph{Update}$\left(s_{t-1}, p_{i}, action \right)$


\section{Related Works}


In our project, we decide to utilize the Reversi, which 
has a different way of attacking, scrambling the opponent in the other chess games, 
 , to implement an agent that could learn the 
specific strategy to try to beat other agents online 
or even people. 

\section{Feature Extraction}
\subsection{Dataset}

%\begin{algorithm}[h]
%	\caption{Get available actions and Flipping points}
%	\begin{algorithmic}[1]
%		\Function {Flipping}{$id, board$}
%      \State $AvailAct \gets \left\{\right\}$
%      \State $FlipP \gets \left\{\right\}$
%      \For {$Points \gets \left(x, y\right), x,y \gets range\left(0, 8\right) $}
%         
%         \State $Row = boards\left[x, :\right]$
%         \State $Column = boards\left[:, y\right]$
%         \State $Diag_1 = diag_1\left(boards\left[x, y\right]\right)$
%         \State $Diag_2 = diag_2\left(boards\left[x, y\right]\right)$
%         \State $LineSet \gets \left\{Row, Column, Diag_1, Diag_2\right\}$
%
%         \For {$lines \in LineSet$}
%
%            \For {$Ps = lines\left(Points:\right)$}
%               \State \textbf{If} $\exists t, Ps[1:t-1] ==-id \textbf{\&} Ps[0] == id \textbf{\&} Ps[t] == id$ \textbf{then}
%                  \State \ \ \ \ \ $AvailAct \gets AvailAct \cup \left\{Points\right\}$
%                  \State \ \ \ \ \ $FlipP = FlipP \cup \left\{Ps[1:t-1]\right\}$
%               \State \textbf{Endif}
%            \EndFor
%
%            \For {$Ps \in lines\left(:Points\right)$}
%            \State \textbf{If} $\exists t, Ps[1:t-1] == -id \textbf{\&} Ps[0] == id \textbf{\&} Ps[t] == id$ \textbf{then}
%            \State \ \ \ \ \ $AvailAct \gets AvailAct \cup \left\{Points\right\}$
%            \State \ \ \ \ \ $FlipP = FlipP \cup \left\{Ps[1:t-1]\right\}$               \State \textbf{Endif}
%            \EndFor
%         \EndFor
%
%      \EndFor
%		\State \Return $AvailAct, FlipP$
%	
%      \EndFunction
%      
%	\end{algorithmic}
%\end{algorithm}

\subsection{Word2vec}

Players in the Reversi aim to get more positions in 
the limited 8 $\times$ 8 space chess board, so the 
basic strategy for the beginer of this game is to 
flip more opponent's chess in each transaction $t$.

\subsubsection{One-hot Coding}

However, the most important thing is that the space 
is limited for the player, the weight of position can 
be strongly different from one to another.

\subsection{CBOW Model}

What's more, when one player is trying to flip his 
opponent's chess, the opponent is also trying to flip 
his. 

\subsection{N-gram Model}

The players have to design a strategy to help them 
to occupy more edges and corners in the game, also to 
defend themselves from being flipped.

\section{Model for Prediction}

\section{Experiments and Results}

\section{Discussion}

\section{Conclusion}
%-------------------------------------------------------------------------
After several algorithm updates, MiniMax Dueling DQN is the most powerful algorithm at present, and the interval time of each drop is very short, so there is almost no waiting time for people. This algorithm not only effectively approximates the q-value through Dueling DQN, but also can consider the advantages of MiniMax in the future step, while avoiding the disadvantages of long calculation time of MiniMax algorithm. There is no battle with the MCTS algorithm in chess, but it is certain that MiniMax Dueling DQN is superior to MCTS in time. The MCTS algorithm will be completed later and the two will be compared.


\section{Contribution}


{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
